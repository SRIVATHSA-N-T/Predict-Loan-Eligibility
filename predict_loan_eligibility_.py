# -*- coding: utf-8 -*-
"""Predict Loan Eligibility .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wna1MhPz5PIjkw5M9RCnUNGmQ5iUwNdm

# ***Predict Loan Eligibility for Dream Housing Finance company***

* Dream Housing Finance company deals in all kinds of home loans. They have presence across all urban, semi urban and rural areas. Customer first applies for home loan and after that company validates the customer eligibility for loan.



* Company wants to automate the loan eligibility process (real time) based on customer detail provided while filling online application form. These details are Gender, Marital Status, Education, Number of Dependents, Income, Loan Amount, Credit History and others. To automate this process, they have provided a dataset to identify the customers segments that are eligible for loan amount so that they can specifically target these customers.

## ***`Data Dictionary`***

**Variable	Description**

 **bold text**
Loan_ID	Unique Loan ID

Gender	Male/ Female

Married	Applicant married (Y/N)

Dependents	Number of dependents

Education	Applicant Education (Graduate/ Under Graduate)

Self_Employed	Self employed (Y/N)

ApplicantIncome	Applicant income

CoapplicantIncome	Coapplicant income

LoanAmount	Loan amount in thousands

Loan_Amount_Term	Term of loan in months

Credit_History	credit history meets guidelines

Property_Area	Urban/ Semi Urban/ Rural

Loan_Status	(Target) Loan approved (Y/N)

## ***Importing Libraries***
"""

# Commented out IPython magic to ensure Python compatibility.
#import Neccessory libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import missingno

from sklearn.preprocessing import StandardScaler

from sklearn.model_selection import train_test_split, GridSearchCV

#import required accuracy metrics
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.metrics import roc_curve, roc_auc_score
from sklearn.model_selection import KFold, cross_val_score

import warnings
warnings.filterwarnings('ignore')
# %matplotlib inline

#loading the data set
df = pd.read_csv(r"/content/train_ctrUa4K.csv")
df.head(5)

#lets check the shape 
print('Shape of train dataset:',df.shape)

#check the data types
df.dtypes

#lets check for Null Values
df.isnull().sum()

missingno.bar(df, figsize = (10,20), color="tab:green")

#lets check for Null Values
df.isnull().sum()

df.drop(columns = 'Loan_ID', inplace = True)

df.head(2)

"""## **Filling missing values**"""

#Lets replace null values from all missing  numerical columns with the mean value of that column
df["LoanAmount"].fillna(df["LoanAmount"].mean(),inplace=True)
df["Loan_Amount_Term"].fillna(df["Loan_Amount_Term"].mean(),inplace=True)
df["Credit_History"].fillna(df["Credit_History"].mean(),inplace=True)

#Lets replace null values from  all missing  Categorical columns with the mean value of that column
df['Gender'] = df['Gender'].fillna(df['Gender'].mode()[0])
df['Married'] = df['Married'].fillna(df['Married'].mode()[0])
df['Self_Employed'] = df['Self_Employed'].fillna(df['Self_Employed'].mode()[0])

df.Dependents.unique()

column = ['Dependents']
for i in column:
    df[i] = df[i].replace({'3+':3, np.nan:0})

#lets check for Null Values
df.isnull().sum()

"""Converting Dependent column data type from Object to integer"""

#lets convert TotalCharges to numeric data
df["Dependents"]=df["Dependents"].str.strip()
df["Dependents"]=pd.to_numeric(df["Dependents"])

df.dtypes

"""Here in our data set on the bases of some observations we can say that some values are given as ? mark, we need to replace them with suitable values."""

#Lets check which columns contains '?'
df[df.columns[(df == '?').any()]].nunique()

#Lets chcek the value counts for categorical data
for i in df.columns:
    if df[i].dtypes == 'object':
        print(df[i].value_counts())
        print('---------'*10)

for col in df.columns:
    print(col,df[col].nunique())
    print('-'*35)

"""# ***EDA***"""

#lets check distribution for continuous columns
num_data = df._get_numeric_data()
plt.figure(figsize = (10,15))
plotnumber = 1
for column in num_data:
    if plotnumber <=10:
        ax = plt.subplot(17,5,plotnumber)
        sns.distplot(num_data[column])
        plt.xlabel(column,fontsize = 10)
    plotnumber+=1
plt.tight_layout()

#lets check relation between gender and Loan_Status
sns.countplot(x = 'Gender', hue = 'Loan_Status', data = df)
plt.show()

#lets check the fraud_report based on age
plt.figure(figsize = (8,5))
sns.countplot(x = 'Gender', hue = 'Property_Area', data = df)
plt.show()

#lets check the fraud_report based on age
plt.figure(figsize = (8,5))
sns.countplot(x = 'Loan_Status', hue = 'Property_Area', data = df)
plt.show()

#lets check relation between Maried and Loan_Status
sns.countplot(x = 'Married', hue = 'Loan_Status', data = df)
plt.show()

#lets check relation between gender and churn
sns.countplot(x = 'Dependents', hue = 'Loan_Status', data = df)
plt.show()

#lets check counts for Education
plt.style.use('fivethirtyeight')
sns.countplot(x = 'Education', data = df)
plt.show()

#check the relation between column Education and Loan Status
sns.countplot(x = 'Education', hue = 'Loan_Status', data = df)
plt.show()

#lets check counts for Self_Employed Y/N
sns.countplot(x = 'Self_Employed',hue = 'Loan_Status', data = df)
#plt.legend( bbox_to_anchor = (1.05, 1), loc = 'upper left')
plt.show()

#check the relation between column Education and Loan Status
sns.countplot(x = 'Property_Area', hue = 'Loan_Status', data = df)
plt.show()

#lets plot barplot for MonthlyCharges vs churn
sns.barplot(x = 'Loan_Status', y = 'Credit_History', data = df)
plt.show()

#lets check counts for Self_Employed Y/N
sns.countplot(x = 'Credit_History',hue = 'Loan_Status', data = df)
plt.show()

#lets have a look on our target variable
sns.countplot(df['Loan_Status'])
print(df['Loan_Status'].value_counts())
plt.show()

"""Here we see that nearly 50% people are not getting loan."""

#lets check the relation between Dependents, TotalCharges, churn using Violin plot
plt.style.use('default')
sns.catplot(x="Self_Employed", y="Dependents", hue="Loan_Status",
            kind="violin", split=True,
            palette="pastel", data=df)
plt.show()

#lets check the relation between Dependents, TotalCharges, churn using Violin plot
plt.style.use('default')
sns.catplot(x="Self_Employed", y="ApplicantIncome", hue="Loan_Status",
            kind="violin", split=True,
            palette="pastel", data=df)
plt.show()

#lets check the relation between Property_Area, Loan_amount_Term and loan status using Violin plot
sns.catplot(x="Property_Area", y="Loan_Amount_Term", hue="Loan_Status",
            kind="violin", split=True,
            palette="pastel", data=df)
plt.show()

#lets check the relation between Property_Area, Loan_amount_Term and loan status using Violin plot
sns.catplot(x="Property_Area", y="LoanAmount", hue="Loan_Status",
            kind="violin", split=True,
            palette="pastel", data=df)
plt.show()

#lets have a look at destribution of Loan_Amount_Term
sns.distplot(df['Loan_Amount_Term'])
plt.show()

#lets have a look on capital gains
sns.distplot(df['LoanAmount'])
plt.show()

#lets have a look on capital gains
sns.distplot(df['CoapplicantIncome'])
plt.show()

#lets have a look on capital gains
sns.distplot(df['ApplicantIncome'])
plt.show()

#if you want to group many columns you can use like date

# plotting barplot for Loan_ID vs LoanAmount (1000)
#fig = plt.figure(figsize=(5,3))
#ax = df.groupby('Loan_ID').LoanAmount.count().plot.bar(ylim=0)
#ax.set_ylabel('Loan Amount in thousands')
#plt.show()

#Lets have a look on loan_status_relationship, how it is distributed
plt.figure(figsize=(10, 6))
plt.pie( df["Property_Area"].value_counts().values, labels = df["Property_Area"].value_counts().index, autopct='%1.1f%%')
fig = plt.gcf()
plt.title('Property_Area  ')
plt.axis('equal')
plt.legend(prop={'size': 12})
plt.legend( bbox_to_anchor = (1.05, 1), loc = 'upper left')
plt.show()

#Lets have a look on loan_status_relationship, how it is distributed
plt.figure(figsize=(10, 6))
plt.pie( df["Married"].value_counts().values, labels = df["Married"].value_counts().index, autopct='%1.1f%%')
fig = plt.gcf()
plt.title('Married  ')
plt.axis('equal')
plt.legend(prop={'size': 12})
plt.legend( bbox_to_anchor = (1.05, 1), loc = 'upper left')
plt.show()

"""---



---

# ***Data processing***

## **Apply label encoder to target variable**
"""

from sklearn.preprocessing import LabelEncoder
leb_enc = LabelEncoder()
df2 = leb_enc.fit_transform(df["Loan_Status"])
pd.Series(df2)
df["Loan_Status"] = df2

"""## Heat map for checking correlation"""

#Lets plot heatmap to check correlation among differnt features and label
df_corr = df.corr()
plt.figure(figsize = (10,5))
sns.heatmap(df_corr,vmin=-1,vmax=1,annot=True,center=0,fmt='.2g',linewidths=0.1)
plt.tight_layout()

#lets describe the data
df.describe().T

"""## Checking for outliers using box plots"""

#lets check outliers from continuous columns
num_data = df._get_numeric_data()
plt.figure(figsize = (25,10))
plotnumber = 1
for column in num_data:
    if plotnumber <=10:
        ax = plt.subplot(5,4,plotnumber)
        sns.boxplot(num_data[column])
        plt.xlabel(column,fontsize = 20)
    plotnumber+=1
plt.tight_layout()

"""## **Removing Outliers**"""

#lets remove outliers using zscore method
#from scipy import stats
#from scipy.stats import zscore
#z_score = zscore(df[["age","policy_annual_premium","umbrella_limit","total_claim_amount","property_claim"]])
#abs_z_score = np.abs(z_score)
#filtering_entry = (abs_z_score < 3).all(axis = 1)
#df = df[filtering_entry]
#df.reset_index(inplace = True)

#lets see the destribution of numerical data
num_data = df._get_numeric_data()
plt.figure(figsize = (25,20))
plt.style.use('fivethirtyeight')
plotnumber = 1
for column in num_data:
    if plotnumber <=5:
        ax = plt.subplot(3,2,plotnumber)
        sns.distplot(num_data[column])
        plt.xlabel(column,fontsize = 20)
    plotnumber+=1
plt.tight_layout()

#lets check for skewness
df.skew()

"""# Separate features and label as x & y respectively"""

x = df.drop(columns = 'Loan_Status')
y = df['Loan_Status']

x.skew()

#Lets treat the skewness from numerical columns
for index in x.skew().index:
    if x.skew().loc[index]>0.5:
        x[index]=np.log1p(x[index])
    if x.skew().loc[index]<-0.5:
        x[index]=np.cbrt(x[index])

#check the skewness again
x.skew()

#lets separate numerical and categorical features for scaling and encoding
num = x._get_numeric_data()
cat = x.select_dtypes(include=['object'])

"""## Applying StandardScaler to numerical features"""

#Lets bring all numerical features to common scale by applying standard scaler
scaler = StandardScaler()
x_num = scaler.fit_transform(num)
x_num = pd.DataFrame(x_num,columns=num.columns)

#combine both numerical and categorical features
X = pd.concat([x_num,cat], axis = 1)

#lets have a look at our features
X.head()

"""## **Encoding**"""

#lets convert categorical data into numeric values, using OrdinalEncoder
from sklearn.preprocessing import OrdinalEncoder
enc = OrdinalEncoder()
for i in X.columns:
    if X[i].dtypes == "object" :
        X[i] = enc.fit_transform(X[i].values.reshape(-1,1))

#lets have a look at data after encoding
X.head()

#check the shape
X.shape

#check value count for target variable
y.value_counts()

"""We can see that this is a case of imbalance, so will do oversampling

## **Over sampling**
"""

#lets drop Dependdent column
X.drop(columns = 'Dependents', inplace = True)

#lets do oversampling using SMOTE
import imblearn
from imblearn.over_sampling import SMOTE
SM = SMOTE()
x_over,y_over = SM.fit_resample(X,y)

#lets check the count of target variable now
y_over.value_counts()

"""# Finding Best random state"""

#Lets find the best random state using LogisticRegression
from sklearn.linear_model import LogisticRegression
max_accu = 0
max_rs = 0
for i in range(50,100):
    x_train,x_test,y_train,y_test = train_test_split(x_over,y_over,test_size = 0.25, random_state = i)
    LR = LogisticRegression()
    LR.fit(x_train,y_train)
    pred = LR.predict(x_test)
    acc = accuracy_score(y_test,pred)
    if acc > max_accu:
        max_accu = acc
        max_rs = i
print("Best accuracy is",max_accu,"on Random State",max_rs)

#lets split our data into train and test parts with best random_state
x_train,x_test,y_train,y_test = train_test_split(x_over, y_over, test_size = 0.25, random_state = 62)

"""## **Model Building with Evaluation Metrics**

## **LogisticRegression model**
"""

#Lets check the model with LogisticRegression
LR.fit(x_train,y_train)
predlr = LR.predict(x_test)
accuracy = accuracy_score(y_test,predlr)*100

print(f"Accuracy Score:", accuracy)
print(f"roc_auc_score: {roc_auc_score(y_test,predlr)*100}")
print("---------------------------------------------------")

#confusion matrix & classification report
print(f"Confusion Matrix : \n {confusion_matrix(y_test,predlr)}\n")
print(f"CLASSIFICATION REPORT : \n {classification_report(y_test,predlr)}")

#cross validation score
scores = cross_val_score(LR, x_over, y_over, cv = 5,scoring = "accuracy" ).mean()*100
print("\nCross validation score :", scores)

#result of accuracy minus cv score
result = accuracy - scores
print("\nAccuracy Score - Cross Validation Score :", result)

"""## **DecisionTreeClassifier model**"""

#model with DecesionTreeClassifier
from sklearn.tree import DecisionTreeClassifier
dt = DecisionTreeClassifier()
dt.fit(x_train,y_train)
pred_dt = dt.predict(x_test)
accuracy = accuracy_score(y_test,pred_dt)*100

print(f"Accuracy Score:", accuracy)
print(f"roc_auc_score: {roc_auc_score(y_test,pred_dt)*100}")
print("---------------------------------------------------")

#confusion matrix & classification report
print(f"Confusion Matrix : \n {confusion_matrix(y_test,pred_dt)}\n")
print(f"CLASSIFICATION REPORT : \n {classification_report(y_test,pred_dt)}")

#cross validation score
scores = cross_val_score(dt, x_over, y_over, cv = 5,scoring = "accuracy" ).mean()*100
print("\nCross validation score :", scores)

#result of accuracy minus cv score
result = accuracy - scores
print("\n\nAccuracy Score - Cross Validation Score :", result)

"""## **RandomForestClassifier model**"""

#model with RandomForestClassifier
from sklearn.ensemble import RandomForestClassifier
rf = RandomForestClassifier()
rf.fit(x_train,y_train)
pred_rf = rf.predict(x_test)
accuracy = accuracy_score(y_test,pred_rf)*100

print(f"Accuracy Score:", accuracy)
print(f"\nroc_auc_score: {roc_auc_score(y_test,pred_rf)*100}")
print("---------------------------------------------------")

#confusion matrix & classification report
print(f"Confusion Matrix : \n {confusion_matrix(y_test,pred_rf)}\n")
print(f"CLASSIFICATION REPORT : \n {classification_report(y_test,pred_rf)}")

#cross validation score
scores = cross_val_score(rf, x_over, y_over, cv = 5,scoring = "accuracy" ).mean()*100
print("\nCross validation score :", scores)

#result of accuracy minus cv score
result = accuracy - scores
print("\n\nAccuracy Score - Cross Validation Score :", result)

"""## **KNeighborsClassifier model**"""

#model with KNeighborsClassifier
from sklearn.neighbors import KNeighborsClassifier
kn = KNeighborsClassifier()
kn.fit(x_train,y_train)
pred_kn = kn.predict(x_test)
accuracy = accuracy_score(y_test,pred_kn)*100

print(f"Accuracy Score:", accuracy)
print(f"roc_auc_score: {roc_auc_score(y_test,pred_kn)*100}")
print("---------------------------------------------------")

#confusion matrix & classification report
print(f"Confusion Matrix : \n {confusion_matrix(y_test,pred_kn)}\n")
print(f"CLASSIFICATION REPORT : \n {classification_report(y_test,pred_kn)}")

#cross validation score
scores = cross_val_score(kn, x_over, y_over, cv = 5,scoring = "accuracy" ).mean()*100
print("\nCross validation score :", scores)

#result of accuracy minus cv score
result = accuracy - scores
print("\n\nAccuracy Score - Cross Validation Score :", result)

"""## **XGBClassifier model**"""

#lets check with XGBClassifier model
from xgboost import XGBClassifier
xgb = XGBClassifier(verbosity = 0)
xgb.fit(x_train,y_train)
pred_xgb = xgb.predict(x_test)
accuracy = accuracy_score(y_test,pred_xgb)*100

print(f"Accuracy Score:", accuracy)
print(f"roc_auc_score: {roc_auc_score(y_test,pred_xgb)*100}")
print("---------------------------------------------------")

#confusion matrix & classification report
print(f"Confusion Matrix : \n {confusion_matrix(y_test,pred_xgb)}\n")
print(f"CLASSIFICATION REPORT : \n {classification_report(y_test,pred_xgb)}")

#cross validation score
scores = cross_val_score(xgb, x_over, y_over, cv = 5,scoring = "accuracy" ).mean()*100
print("\nCross validation score :", scores)

#result of accuracy minus cv score
result = accuracy - scores
print("\nAccuracy Score - Cross Validation Score :", result)

"""## **ExtraTreesClassifier model**"""

#lets check with Extra Trees Classifier
from sklearn.ensemble import ExtraTreesClassifier
ext = ExtraTreesClassifier()
ext.fit(x_train,y_train)
pred_ext = xgb.predict(x_test)
accuracy = accuracy_score(y_test,pred_ext)*100

print(f"Accuracy Score:", accuracy)
print(f"roc_auc_score: {roc_auc_score(y_test,pred_ext)*100}")
print("---------------------------------------------------")

#confusion matrix & classification report
print(f"Confusion Matrix : \n {confusion_matrix(y_test,pred_ext)}\n")
print(f"CLASSIFICATION REPORT : \n {classification_report(y_test,pred_ext)}")

#cross validation score
scores = cross_val_score(ext, x_over, y_over, cv = 5,scoring = "accuracy" ).mean()*100
print("\nCross validation score :", scores)

#result of accuracy minus cv score
result = accuracy - scores
print("\nAccuracy Score - Cross Validation Score :", result)

"""## **AUC & ROC Curve**"""

#Lets plot roc curve and check auc and performance of all algorithms
from sklearn.metrics import plot_roc_curve
disp = plot_roc_curve(LR, x_test, y_test)
plot_roc_curve(dt, x_test, y_test, ax = disp.ax_)
plot_roc_curve(rf, x_test, y_test, ax = disp.ax_)
plot_roc_curve(kn, x_test, y_test, ax = disp.ax_)
plot_roc_curve(xgb, x_test, y_test, ax = disp.ax_)
plot_roc_curve(ext, x_test, y_test, ax = disp.ax_)
plt.figure(figsize = (25,25))
plt.show()

"""We can see KNeighborsClassifier is giving least difference in accuracy and cv score but its AUC is very less


RandomForestClassifier is giving least in accuracy and cv score next to KNeighborsClassifier, and its AUC also High, that is it is showing better model performance than KNeighborsClassifier.


ExtraTreesClassifier and XGBClassifier are showing almost same AUC as RandomForestClassifier, but their the difference in accuracy and cv score is higher than RandomForestClassifier.


Considering above observations I am selecting RandomForestClassifier as a best suitable algorithm for this model.

## **Hyperparameter Tuning**
"""

#lets selects different parameters for tuning
grid_params = {
               'criterion':['gini','entropy'],
                'max_depth': [10,12,15,20,22],
                'n_estimators':[500,700,1000,1200],
                'max_features':['aoto','sqrt','log2'],
                'min_samples_split': [2]
                }

#train the model with given parameters using GridSearchCV
GCV =  GridSearchCV(RandomForestClassifier(), grid_params, cv = 5)
GCV.fit(x_train,y_train)

GCV.best_params_       #printing the best parameters found by GridSearchCV

#lets check the results of final model with best parameters
model = RandomForestClassifier(criterion = 'gini', max_depth = 22, min_samples_split = 2,  n_estimators = 1200)
model.fit(x_train,y_train)
pred = model.predict(x_test)

print(f"Accuracy Score: {accuracy_score(y_test,pred)*100}%")
print("--------------------------------------------------------")

print(f"roc_auc_score: {roc_auc_score(y_test,pred)*100}%")
print("--------------------------------------------------------")

print(f"Confusion Matrix : \n {confusion_matrix(y_test,pred)}\n")
print("------------------------------------------------------------------------")
print(f"CLASSIFICATION REPORT : \n {classification_report(y_test,pred)}")

"""Great we have got improved accuracy after hyperparameter tuning.

## **AUC ROC CURVE for final model**
"""

plot_roc_curve(model, x_test, y_test)
plt.title('ROC Curve for best model')
plt.show()

"""Great after hyperparameter tuning we got improvement in roc curve and AUC also.

# ***Test_Data_Set***
"""

test = pd.read_csv('/content/test_lAUu6dG.csv')
test.head(5)

L_ID = test['Loan_ID']
test = test.drop(columns='Loan_ID')

test.shape

test.info()

test.isna().sum()

"""Treating null values"""

#Lets replace null values from all missing  numerical columns with the mean value of that column
test["LoanAmount"].fillna(test["LoanAmount"].mean(),inplace=True)
test["Loan_Amount_Term"].fillna(test["Loan_Amount_Term"].mean(),inplace=True)
test["Credit_History"].fillna(test["Credit_History"].mean(),inplace=True)

#Lets replace null values from  all missing  Categorical columns with the mean value of that column
test['Gender'] = test['Gender'].fillna(test['Gender'].mode()[0])
test['Married'] = test['Married'].fillna(test['Married'].mode()[0])
test['Self_Employed'] = test['Self_Employed'].fillna(test['Self_Employed'].mode()[0])

column = ['Dependents']
for i in column:
    test[i] = test[i].replace({'3+':3, np.nan:0})

test.isna().sum()

test.dtypes

#lets convert TotalCharges to numeric data
test["Dependents"]=test["Dependents"].str.strip()
test["Dependents"]=pd.to_numeric(test["Dependents"])

test.dtypes

#Lets check which columns contains '?'
df[df.columns[(df == '?').any()]].nunique()

#lets separate numerical and categorical features for scaling and encoding
num = test._get_numeric_data()
cat = test.select_dtypes(include=['object'])

#Lets bring all numerical features to common scale by applying standard scaler
scaler = StandardScaler()
test_num = scaler.fit_transform(num)
test_num = pd.DataFrame(test_num,columns=num.columns)

#combine both numerical and categorical features
test = pd.concat([test_num,cat], axis = 1)

test.head(5)

#lets convert categorical data into numeric values, using OrdinalEncoder
from sklearn.preprocessing import OrdinalEncoder
enc = OrdinalEncoder()
for i in test.columns:
    if test[i].dtypes == "object" :
        test[i] = enc.fit_transform(test[i].values.reshape(-1,1))

#lets drop Dependdent column
test.drop(columns = 'Dependents', inplace = True)

test.shape

test.head(5)

#lets predict the price with our best model
prediction = model.predict(test)

prediction

#lets make the dataframe for prediction
Loan_st = pd.DataFrame(prediction, columns=["Loan_Status"])

Loan_st.shape

#Loan_ID = test.drop(columns = 'Loan_ID')
#Loan_ID = test['Loan_ID']

Loan_st.shape

Loan_ID.shape

loan_file = pd.concat([L_ID, Loan_st], axis = 1)

loan_file.head(5)

loan_file['Loan_Status']= loan_file['Loan_Status'].replace({0.0:'N',1.0:'Y'})

loan_file.head(5)

loan_file.shape

#Lets save the submission to csv
loan_file.to_csv("predicted_loan_status.csv",index=False)

"""# ***Thank You***"""